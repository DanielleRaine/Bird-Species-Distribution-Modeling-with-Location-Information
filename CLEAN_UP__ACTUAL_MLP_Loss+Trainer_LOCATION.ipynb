{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielleRaine/Bird-Species-Distribution-Modeling-with-Location-Information/blob/main/CLEAN_UP__ACTUAL_MLP_Loss%2BTrainer_LOCATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM-W2wT-SC-d",
        "outputId": "11b3dad4-a1db-4d75-b378-796b7be92188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbimporter in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.10/dist-packages (0.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.10.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.9.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.7.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.21.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.13)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.47.3)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.18.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.3)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.6)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.9.4)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbimporter\n",
        "!pip install import-ipynb\n",
        "!pip install torch\n",
        "!pip install torcheval\n",
        "!pip install torchmetrics\n",
        "!pip install comet-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuGHkGv5BDHt",
        "outputId": "80a7da56-8e66-41c9-b3b7-c18827fc825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from typing import Any\n",
        "from ctypes import sizeof\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torcheval.metrics import MeanSquaredError\n",
        "from torchmetrics.regression import MeanAbsoluteError\n",
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2awrCJN95kt5"
      },
      "outputs": [],
      "source": [
        "class BirdHotspotsDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Dataset for Bird Species Distribution Modeling with Location Information (Bird Hotspots).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, features_df, targets_df):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      features_df (pd.DataFrame): DataFrame containing the features.\n",
        "      targets_df (pd.DataFrame): DataFrame containing the targets.\n",
        "    \"\"\"\n",
        "\n",
        "    self.data = [\n",
        "        [torch.tensor(pd.to_numeric(row.drop(labels = [\"hotspot_id\"]).values, errors = \"coerce\")).squeeze(),\n",
        "         torch.tensor(targets_df.loc[targets_df[\"hotspot_id\"] == row[\"hotspot_id\"]]\n",
        "                                    .drop(columns = [\"hotspot_id\", \"num_complete_checklists\"]).values).squeeze()]\n",
        "                 for i, row in features_df.iterrows()]\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Returns the length of the dataset.\n",
        "    Returns:\n",
        "      length (int): Length of the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Returns the record and its target.\n",
        "    Args:\n",
        "      idx (int): Index of the record.\n",
        "    Returns:\n",
        "      record (torch.Tensor): Record.\n",
        "      target (torch.Tensor): Target.\n",
        "    \"\"\"\n",
        "\n",
        "    return self.data[idx][0], self.data[idx][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogiVsZeBax4B"
      },
      "outputs": [],
      "source": [
        "# Data that includes location data\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/TeamMila/ProjectDataset/normalized_train_loc.csv')\n",
        "df_val = pd.read_csv('/content/drive/MyDrive/TeamMila/ProjectDataset/normalized_val_loc.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/TeamMila/ProjectDataset/normalized_test_loc.csv')\n",
        "df_targets = pd.read_csv('/content/drive/MyDrive/TeamMila/ProjectDataset/targets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns that will be used for the data\n",
        "df_columns = [\"hotspot_id\", \"lon\", \"lat\"] + [f\"bio_{i}\" for i in range(1, 20)] + [\"orcdrc\", \"phihox\", \"cecsol\", \"bdticm\", \"clyppt\", \"sltppt\", \"sndppt\", \"bldfie\"]"
      ],
      "metadata": {
        "id": "2862jVuFOcNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[df_columns]\n",
        "df_val = df_val[df_columns]\n",
        "df_test = df_test[df_columns]"
      ],
      "metadata": {
        "id": "UV_yKnywOPmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xctK1zUdAcd"
      },
      "outputs": [],
      "source": [
        "train_dataset = BirdHotspotsDataset(df_train, df_targets)\n",
        "valid_dataset = BirdHotspotsDataset(df_val, df_targets)\n",
        "test_dataset = BirdHotspotsDataset(df_test, df_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8SoBzQfcsBz"
      },
      "outputs": [],
      "source": [
        "# Pickle each dataset\n",
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/train_dataset_loc.p', 'wb') as f:\n",
        "    pickle.dump(train_dataset, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/valid_dataset_loc.p', 'wb') as f:\n",
        "    pickle.dump(valid_dataset, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/test_dataset_loc.p', 'wb') as f:\n",
        "    pickle.dump(test_dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Q3EAwXVSiK"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/train_dataset_loc.p', \"rb\") as f:\n",
        "  train_dataset = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/valid_dataset_loc.p', \"rb\") as f:\n",
        "  valid_dataset = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/TeamMila/ProjectDataset/test_dataset_loc.p', \"rb\") as f:\n",
        "   test_dataset = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx0UBoRmCmSl"
      },
      "outputs": [],
      "source": [
        "# different datloaders for different splits of the data\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1FOfwCE1hm"
      },
      "outputs": [],
      "source": [
        "class EncounterRateMLP(nn.Module):\n",
        "    def __init__(self, env_input_size=27, loc_input_size=2, num_classes=1, hidden_dimensions=128):\n",
        "        super(EncounterRateMLP, self).__init__()\n",
        "        self.inc_bias = False\n",
        "        # Encoder for environmental features\n",
        "        self.env_encoder = nn.Sequential(\n",
        "            nn.Linear(env_input_size, hidden_dimensions),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Linear(hidden_dimensions, hidden_dimensions),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "        # Encoder for location features\n",
        "        self.loc_encoder = nn.Sequential(\n",
        "            nn.Linear(loc_input_size, hidden_dimensions),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Linear(hidden_dimensions, hidden_dimensions),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "        # Final output layer after concatenating encoded features\n",
        "        self.output_layer = nn.Linear(hidden_dimensions * 2, num_classes)\n",
        "    def forward(self, env_features, loc_features):\n",
        "        # Pass through environmental encoder\n",
        "        env_encoded = self.env_encoder(env_features)\n",
        "        # Pass through location encoder\n",
        "        loc_encoded = self.loc_encoder(loc_features)\n",
        "        # Concatenate encoded features\n",
        "        combined_features = torch.cat((env_encoded, loc_encoded), dim=1)\n",
        "        # Pass through final output layer and apply sigmoid\n",
        "        output = torch.sigmoid(self.output_layer(combined_features))\n",
        "        return output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4HQUbuJcA-3"
      },
      "outputs": [],
      "source": [
        "def TopKAccuracy(outputs, targets, k = None):\n",
        "    if k is None:\n",
        "        # Let K be the number of nonzero values for a set of predictions\n",
        "        sum_correct = 0\n",
        "        batch_size = outputs.shape[0]\n",
        "        for output, target in zip(outputs, targets):\n",
        "            k = torch.count_nonzero(target).item()\n",
        "            top_k_preds = torch.topk(output, k, dim=0).indices\n",
        "            true_labels = torch.topk(target, k, dim=0).indices\n",
        "            sum_correct += torch.any(top_k_preds == true_labels)\n",
        "        correct = sum_correct / batch_size\n",
        "        return correct\n",
        "\n",
        "    # Get the top K predictions' indices\n",
        "    top_k_preds = torch.topk(outputs, k, dim=1).indices\n",
        "    true_labels = torch.topk(targets, k, dim=1).indices\n",
        "\n",
        "    # Check if the true label is in the top K predictions\n",
        "    correct = torch.any(top_k_preds == true_labels, dim=1)\n",
        "\n",
        "    # Return the average success of the batch of predictions\n",
        "    return correct.float().mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU2W-ChlR8or"
      },
      "outputs": [],
      "source": [
        "def training_step(model, dataloader, eval_dataloader, criterion, optimizer, device, checkpoint_dir, num_epochs, experiment = None):\n",
        "    model.to(device)\n",
        "    best_loss = float('inf')\n",
        "    last_checkpoint_path = os.path.join(checkpoint_dir, 'last_checkpoint.pth')\n",
        "    best_checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
        "    mse_metric = MeanSquaredError().to(device)\n",
        "    mae_metric = MeanAbsoluteError().to(device)\n",
        "    mse_metric_eval = MeanSquaredError().to(device)\n",
        "    mae_metric_eval = MeanAbsoluteError().to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        mse_metric.reset()\n",
        "        mae_metric.reset()\n",
        "        mse_metric_eval.reset()\n",
        "        mae_metric_eval.reset()\n",
        "\n",
        "        print(\"A NEW EPOCH HAS STARTED\")\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        top_10_correct = 0\n",
        "        top_30_correct = 0\n",
        "        top_k_correct = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        top_10_correct_eval = 0\n",
        "        top_30_correct_eval = 0\n",
        "        top_k_correct_eval = 0\n",
        "        num_batches_eval = 0\n",
        "\n",
        "        for inputs, targets in dataloader:\n",
        "          ### runtime error of having inputs and targets as non-floats\n",
        "          inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs[:, 2:], inputs[:, :2])\n",
        "\n",
        "          #runtime error address: targets not in between 0 to 1\n",
        "          targets = torch.clamp(targets,0,1)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          mse_metric.update(outputs, targets)\n",
        "          mae_metric.update(outputs, targets)\n",
        "\n",
        "          top_10_correct += TopKAccuracy(outputs, targets, k = 10)\n",
        "          top_30_correct += TopKAccuracy(outputs, targets, k = 30)\n",
        "          top_k_correct += TopKAccuracy(outputs, targets)\n",
        "          num_batches += 1\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        print(\"EVAL\")\n",
        "\n",
        "        for inputs, targets in eval_dataloader:\n",
        "          with torch.no_grad():\n",
        "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
        "\n",
        "            outputs = model(inputs[:, 2:], inputs[:, :2])\n",
        "            targets = torch.clamp(targets,0,1)\n",
        "\n",
        "            mse_metric_eval.update(outputs, targets)\n",
        "            mae_metric_eval.update(outputs, targets)\n",
        "\n",
        "            top_10_correct_eval += TopKAccuracy(outputs, targets, k = 10)\n",
        "            top_30_correct_eval += TopKAccuracy(outputs, targets, k = 30)\n",
        "            top_k_correct_eval += TopKAccuracy(outputs, targets)\n",
        "            num_batches_eval += 1\n",
        "\n",
        "        mse = mse_metric.compute()\n",
        "        mae = mae_metric.compute()\n",
        "\n",
        "        top_10 = top_10_correct / num_batches\n",
        "        top_30 = top_30_correct / num_batches\n",
        "        top_k = top_k_correct / num_batches\n",
        "\n",
        "        mse_eval = mse_metric_eval.compute()\n",
        "        mae_eval = mae_metric_eval.compute()\n",
        "\n",
        "        top_10_correct_eval = top_10_correct_eval / num_batches_eval\n",
        "        top_30_correct_eval = top_30_correct_eval / num_batches_eval\n",
        "        top_k_correct_eval = top_k_correct_eval / num_batches_eval\n",
        "\n",
        "        if experiment is not None:\n",
        "          experiment.log_metrics({\n",
        "              \"mse\": mse,\n",
        "              \"mae\": mae,\n",
        "              \"top_10_accuracy\": top_10,\n",
        "              \"top_30_accuracy\": top_30,\n",
        "              \"top_k_accuracy\": top_k,\n",
        "              \"mse_eval\": mse_eval,\n",
        "              \"mae_eval\": mae_eval,\n",
        "              \"top_10_accuracy_eval\": top_10_correct_eval,\n",
        "              \"top_30_accuracy_eval\": top_30_correct_eval,\n",
        "              \"top_k_accuracy_eval\": top_k_correct_eval\n",
        "              }, step=epoch\n",
        "          )\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \" f\"Mean Squared Error: {mse.item():.5f}, \" f\"Mean Absolute Error: {mae.item():.5f}, \" f\"Top 10 Accuracy: {top_10:.5f}, \" f\"Top 30 Accuracy: {top_30:.5f},\" f\" Top K Accuracy: {top_k:.5f}\")\n",
        "\n",
        "        #-----\n",
        "        #below statement has been tested and does work\n",
        "        # torch.save(model.state_dict(), last_checkpoint_path)\n",
        "        #-----\n",
        "\n",
        "        checkpoint = {\n",
        "        'epoch': epoch + 1,  # Save the epoch number (1-based index)\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss.item()\n",
        "        }\n",
        "        #this should save a checkpoint after every epoch [HAVE NOT TESTED]\n",
        "        torch.save(checkpoint, f\"checkpoints_epoch_{epoch+1}.pth\")\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), best_checkpoint_path)\n",
        "        print(f'CURRENT BEST MODEL: {epoch + 1} LOSS: {best_loss:.5f}')\n",
        "\n",
        "\n",
        "    print(f'CURRENT EPOCH: [{epoch + 1}/{num_epochs}], LOSS: {epoch_loss:.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqKlUPz2n1Jb"
      },
      "outputs": [],
      "source": [
        "def testing_step(model, dataloader, device, experiment = None):\n",
        "    model.to(device)\n",
        "\n",
        "    mse_metric = MeanSquaredError().to(device)\n",
        "    mae_metric = MeanAbsoluteError().to(device)\n",
        "\n",
        "    mse_metric.reset()\n",
        "    mae_metric.reset()\n",
        "\n",
        "    top_10_correct = 0\n",
        "    top_30_correct = 0\n",
        "    top_k_correct = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "      inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
        "      outputs = model(inputs[:, 2:], inputs[:, :2])\n",
        "      targets = torch.clamp(targets,0,1)\n",
        "\n",
        "      mse_metric.update(outputs, targets)\n",
        "      mae_metric.update(outputs, targets)\n",
        "\n",
        "      top_10_correct += TopKAccuracy(outputs, targets, k = 10)\n",
        "      top_30_correct += TopKAccuracy(outputs, targets, k = 30)\n",
        "      top_k_correct += TopKAccuracy(outputs, targets)\n",
        "      num_batches += 1\n",
        "\n",
        "    mse = mse_metric.compute()\n",
        "    mae = mae_metric.compute()\n",
        "\n",
        "    top_10 = top_10_correct / num_batches\n",
        "    top_30 = top_30_correct / num_batches\n",
        "    top_k = top_k_correct / num_batches\n",
        "\n",
        "    print(f\"Mean Squared Error: {mse.item():.5f}, Mean Absolute Error: {mae.item():.5f}\")\n",
        "\n",
        "    print(f\"Top 10 Accuracy: {top_10:.5f}, Top 30 Accuracy: {top_30:.5f}, Top K Accuracy: {top_k:.5f}\")\n",
        "\n",
        "    if experiment is not None:\n",
        "      experiment.log_metrics({\n",
        "          \"mse_test\": mse,\n",
        "          \"mae_test\": mae,\n",
        "          \"top_10_accuracy_test\": top_10,\n",
        "          \"top_30_accuracy_test\": top_30,\n",
        "          \"top_k_accuracy_test\": top_k\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDo724uAAPG0"
      },
      "outputs": [],
      "source": [
        "def CrossEntropyLoss(model,predictions,targets):\n",
        "  criterion = nn.BCELoss()\n",
        "  loss = criterion(predictions, targets)\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U35U9s2RcVN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b67eb1-a6d2-400a-9c34-ea71170ff6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/danielleraine/bird-species-distribution-modeling-with-location-information/82bddc364f274f99a0f156c78581e0a7\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        }
      ],
      "source": [
        "# Use 'Secrets' tab to store real api_key value\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=userdata.get('comet_api_key'),\n",
        "    project_name=\"bird-species-distribution-modeling-with-location-information\",\n",
        "    workspace=\"danielleraine\"\n",
        ")\n",
        "\n",
        "experiment.set_name(\"baseline-loc-augnorm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BgP1xUdlnw"
      },
      "outputs": [],
      "source": [
        "hyper_params = {\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_epochs': 10,\n",
        "}\n",
        "\n",
        "experiment.log_parameters(hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn3jG0ilAewO"
      },
      "outputs": [],
      "source": [
        "model = EncounterRateMLP(27, 2, 671, hidden_dimensions=128).float()\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqygLQFrKU0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840c7b8e-7db9-4726-8c71-57714dd31d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [1/10], Mean Squared Error: 0.00994, Mean Absolute Error: 0.02764, Top 10 Accuracy: 0.73379, Top 30 Accuracy: 0.81033, Top K Accuracy: 0.82360\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [2/10], Mean Squared Error: 0.00747, Mean Absolute Error: 0.02408, Top 10 Accuracy: 0.75475, Top 30 Accuracy: 0.83624, Top K Accuracy: 0.84617\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [3/10], Mean Squared Error: 0.00728, Mean Absolute Error: 0.02356, Top 10 Accuracy: 0.75935, Top 30 Accuracy: 0.83863, Top K Accuracy: 0.85077\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [4/10], Mean Squared Error: 0.00717, Mean Absolute Error: 0.02327, Top 10 Accuracy: 0.75937, Top 30 Accuracy: 0.83860, Top K Accuracy: 0.85208\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [5/10], Mean Squared Error: 0.00708, Mean Absolute Error: 0.02305, Top 10 Accuracy: 0.76226, Top 30 Accuracy: 0.84157, Top K Accuracy: 0.85230\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [6/10], Mean Squared Error: 0.00703, Mean Absolute Error: 0.02291, Top 10 Accuracy: 0.76155, Top 30 Accuracy: 0.84392, Top K Accuracy: 0.85404\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [7/10], Mean Squared Error: 0.00700, Mean Absolute Error: 0.02281, Top 10 Accuracy: 0.76419, Top 30 Accuracy: 0.84403, Top K Accuracy: 0.85345\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [8/10], Mean Squared Error: 0.00695, Mean Absolute Error: 0.02271, Top 10 Accuracy: 0.76345, Top 30 Accuracy: 0.84453, Top K Accuracy: 0.85436\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [9/10], Mean Squared Error: 0.00692, Mean Absolute Error: 0.02262, Top 10 Accuracy: 0.76356, Top 30 Accuracy: 0.84641, Top K Accuracy: 0.85653\n",
            "A NEW EPOCH HAS STARTED\n",
            "EVAL\n",
            "Epoch [10/10], Mean Squared Error: 0.00690, Mean Absolute Error: 0.02256, Top 10 Accuracy: 0.76393, Top 30 Accuracy: 0.84673, Top K Accuracy: 0.85671\n",
            "CURRENT BEST MODEL: 10 LOSS: 0.05625\n",
            "CURRENT EPOCH: [10/10], LOSS: 0.05625\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "checkpoint_dir = './checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "last_checkpoint_path = os.path.join(checkpoint_dir, 'last_checkpoint.pth')\n",
        "best_checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
        "\n",
        "# Save model state after each epoch\n",
        "# torch.save(model.state_dict(),\n",
        "#            last_checkpoint_path)\n",
        "loss = 0.0\n",
        "epoch = 0\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss,\n",
        "}, \"best_checkpoint.pth\")\n",
        "\n",
        "training_step(\n",
        "    model=model,\n",
        "    dataloader=train_dataloader,\n",
        "    eval_dataloader=valid_dataloader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    num_epochs=10,  # Number of epochs for training\n",
        "    experiment=experiment\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFVCwR62TdAq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "edd4eaf4-edab-4684-ed10-d3c5db7d4a5f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-121b72e06327>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoints/best_checkpoint.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feats.0.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# checkpoint = torch.load(\"checkpoints/best_checkpoint.pth\")\n",
        "# print(checkpoint.keys())\n",
        "# print(checkpoint['feats.0.weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3aQAJDCm5Je"
      },
      "outputs": [],
      "source": [
        "# torch.save(model, \"/content/drive/MyDrive/TeamMila/Models/baseline-loc-augnorm.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sePuiK61nkUW"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"/content/drive/MyDrive/TeamMila/Models/baseline_model.pth\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IluxScDysxMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120d04f0-477f-4eab-f890-86f121b671aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.00977, Mean Absolute Error: 0.02830\n",
            "Top 10 Accuracy: 0.70994, Top 30 Accuracy: 0.79737, Top K Accuracy: 0.80195\n"
          ]
        }
      ],
      "source": [
        "testing_step(model, test_dataloader, device, experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE96BbvUGUd3"
      },
      "outputs": [],
      "source": [
        "log_model(experiment, model, \"baseline-loc-augnorm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hima5cY9g8u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba6b75a-edf3-4b12-f411-e5c6bdd8b7b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : baseline-loc-augnorm\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/danielleraine/bird-species-distribution-modeling-with-location-information/82bddc364f274f99a0f156c78581e0a7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1337]               : (0.04721482843160629, 28.364704132080078)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mae [10]                  : (0.022451551631093025, 0.02771819196641445)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mae_eval [10]             : (0.024273058399558067, 0.026930954307317734)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mae_test                  : 0.02686145529150963\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mse [10]                  : (0.006865320727229118, 0.010266482830047607)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mse_eval [10]             : (0.007792316377162933, 0.008423596620559692)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mse_test                  : 0.00871006678789854\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_10_accuracy [10]      : (0.719170956533171, 0.7650750137213548)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_10_accuracy_eval [10] : (0.7369576149973376, 0.7473706896962791)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_10_accuracy_test      : 0.727039250217635\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_30_accuracy [10]      : (0.7982146673088387, 0.847605866376553)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_30_accuracy_eval [10] : (0.817643678188324, 0.8308836207307618)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_30_accuracy_test      : 0.8113946577598309\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_k_accuracy [10]       : (0.8138315677642822, 0.8586838245391846)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_k_accuracy_eval [10]  : (0.8257255554199219, 0.8408800363540649)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     top_k_accuracy_test       : 0.8177425861358643\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name         : baseline-loc-augnorm\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url : https://colab.research.google.com/notebook#fileId=1-K34bNOu3AsVrKsvHRVwIjaCNRw6p8RO\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (821.56 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
          ]
        }
      ],
      "source": [
        "experiment.end()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}